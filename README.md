# ViT-Playground-2.0

**ViT-Playground-2.0** is a personal and practical environment designed for training, fine-tuning, LoRA-PEFT, testing, and experimenting with Vision Transformers (ViTs) and other large Transformer backbones. Built on PyTorch and CUDA, this repository supports workflows ranging from large-scale A100 multi-GPU cluster training to lightweight inference on personal CPU only devices.

---

## âœ¨ Features

- ğŸ§  **Train and Fine-tune Vision Transformers**  
  Includes support for standard supervised learning, unsupervised masking methods and lightweight fine-tuning methods like LoRA.

- ğŸ”§ **Modular Architecture**  
  Easily extend or modify transformer components using subclass-based design.

- âš™ï¸ **Multi-Device Compatibility**  
  - âœ… Scalable training on SLURM-based HPC environments (e.g., worked on 640GB 8Ã— A100 GPU cluster)
  - âœ… Fine-tuning on mid-range GPUs (e.g., worked on 6GB RTX 2060 Windows PC)  
  - âœ… Inference and low level module testing on CPU-only machines, including macOS (Tested on M4 MacBook)

- ğŸš€ **Built with PyTorch**  
  It utilizes native, from-scratch PyTorch modules and CUDA acceleration when available, with many test example implementations, such as How Backpropagation Works for transformer parameter updates at the low level.

---

## ğŸ“ Project Structure

ViT-Playground-2.0/
â”œâ”€â”€ src/                 # Core model architecture and utilities
â”œâ”€â”€ train.py             # Entry point for local training
â”œâ”€â”€ main_distributed.py  # Entry point for multi-GPU (e.g., Slurm) training
â”œâ”€â”€ inference.py         # Inference/testing utilities
â”œâ”€â”€ configs/             # YAML config files for various experiments
â””â”€â”€ data/                # Dataset loading and preparation

---

## ğŸ§ª Use Cases

This repo serves as my **testbed for Vision Transformer backbones**. It is actively used to:

- Evaluate different backbone variants under controlled settings
- Compare training behaviors across devices and scales
- Prototype new transformer modules or fine-tuning strategies

---

## ğŸ”§ Requirements

- Python â‰¥ 3.8
- PyTorch â‰¥ 2.0
- CUDA (for GPU acceleration)

You can install the dependencies via:

```bash
pip install -r requirements.txt
```

---

ğŸ“Œ Notes
	â€¢	This repository is actively evolving.
	â€¢	It is tailored for my own research and experimentation but kept general enough for others to adapt.

---

ğŸ–¥ï¸ Example Usage

Train locally:

```bash
python train.py --fname configs/vit_base.yaml
```

Train on multiple GPUs:

```bash
python -m torch.distributed.launch --nproc_per_node=8 main_distributed.py --fname configs/vit_large.yaml
```

---

ğŸ§‘â€ğŸ’» Author

Maintained by @HasithaGallella.

If you find this useful or have suggestions, feel free to open an issue or a pull request.

---

ğŸ“œ License

This project is released under the MIT License.

Let me know if you have any sudgestions to include to make this a more practicle codebase to explore Deep learning framework!
